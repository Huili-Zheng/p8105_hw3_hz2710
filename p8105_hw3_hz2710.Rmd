---
title: "p8105_hw3_hz2710"
author: "Huili Zheng"
date: "10/14/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(p8105.datasets)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(knitr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

Load the datasets.
```{r}
data("instacart")
instacart = instacart
```


## Problem 1 

The goal is to do some exploration of this dataset. 

* **Size and key variables of the dataset** 
The dataset has `r nrow(instacart)` rows and `r ncol(instacart)` columns, including of `r colnames(instacart)` variables. 
The key variables are `product_name`, `aisle`, `reordered`

* **Illustrative example**
`r instacart[1,] %>% knitr::kable()`
Take the first row as an example, we can see the first row shows that an item shopped in an order with id is 1, id of the product is 49302, the first item added in the cart was reordered the first time by a user with id 112108. It was the 4th time for this user. He bought the product at the 10th hour of the day on Thursday. Since the last order, it had been 9 days. The product name is 'Bulgarian Yogurt'. The aisle id and name is 120 and 'yogurt'. The department id and name is 16 and 'dairy eggs'.


* **Answer questions**

* There are `r length(unique(pull(instacart, aisle)))` aisles here, and the most items ordered from `r names(tail(sort(table(pull(instacart, aisle))),1))`. Fresh vegetables are common and necessary supplies.

* A plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. 
```{r}
aisle_plot =
  instacart %>%
  group_by(aisle) %>%
  mutate(
    aisle_count = length(aisle)
  ) %>%
  filter(aisle_count > 10000) %>%
  ggplot(aes(x = aisle)) +
    geom_bar() + 
    scale_x_discrete(guide = guide_axis(angle = 90)) +
    labs(x = "Aisle", y = "Aisle count", title = "Counts of aisle") 

aisle_plot
```

* A table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. 

```{r}
pop_items = 
  instacart %>%
  filter(
    aisle %in% c("baking ingredients","dog food care","packaged vegetables fruits")
  ) %>%
  group_by(aisle,product_name) %>%
  summarize(product_count = length(product_name)) %>%
  mutate(
    product_rank = order(order(product_count, decreasing = TRUE)),
  ) %>%
  filter(product_rank <= 3) %>%
  select(-product_rank) %>%
  knitr::kable(caption = "Three most popular items in the aisles")
```


* A table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

```{r}
mean_hour = 
  instacart %>%
  filter(
    product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")
  ) %>%
  group_by(product_name,order_dow) %>%
  summarize(mean_order_hour = mean(order_hour_of_day)) %>%
  mutate(
    order_dow = case_when(
      order_dow == 1 ~ "Monday",
      order_dow == 2 ~ "Tuesday",
      order_dow == 3 ~ "Wednesday",
      order_dow == 4 ~ "Thursday",
      order_dow == 5 ~ "Friday",
      order_dow == 6 ~ "Saturday",
      order_dow == 0 ~ "Sunday",
    )
  ) %>%
  pivot_wider(names_from = order_dow,
              values_from = mean_order_hour) %>%
  knitr::kable(caption = "Mean hour of the day at which PLA and CIC were ordered on each day of the week")
```

## Problrm 2

Load the data
```{r}
data("brfss_smart2010")
brfss = brfss_smart2010
```

* **Data cleaning**
```{r}
brfss = 
  brfss %>%
  janitor::clean_names() %>%
  rename(
    state = locationabbr,
    location = locationdesc
  ) %>%
  filter(topic == "Overall Health" & response %in% c("Poor", "Fair", "Good", "Very good", "Excellent")) %>%
  mutate(
    response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))
  )
```

* **Answer the question**
```{r}
brfss_2002 = 
  brfss %>%
  filter(year == 2002) %>%
  group_by(state,location) %>%
  summarize() %>%
  summarize(observed_time = n()) %>%
  filter(observed_time >= 7) %>%
  select(state,observed_time)
```

* In 2002, `r unique(pull(brfss_2002,state))` states were observed at 7 or more locations.

```{r}
brfss_2010 = 
  brfss %>%
  filter(year == 2010) %>%
  group_by(state,location) %>%
  summarize() %>%
  summarize(observed_time = n()) %>%
  filter(observed_time >= 7) %>%
  select(state,observed_time)
```

* In 2010, `r unique(pull(brfss_2010,state))` states were observed at 7 or more locations.

```{r,fig.width = 10}
excellent = 
  brfss %>%
  filter(response == "Excellent") %>%
  select(c("year","state","data_value")) %>%
  group_by(state,year) %>%
  mutate(mean_value = mean(data_value, na.rm = TRUE)) %>%
  select(-c(data_value)) %>%
  unique()

excellent_plot = 
  excellent %>%
  ggplot(aes(x = year, y = mean_value, color = state)) +
  geom_line() +
  labs(x = "Year", y = "Mean data value", title = "Average value over time")

excellent_plot
```

* The trend of the average value over time among these state is decreasing during the first 4 years and the gradually rising. The range is from about 15 to 30 exclude that the mean value of WY state in 2005 was extremely low.

```{r}
brfss %>%
  filter(year %in% c(2006,2010) & state == "NY") %>%
  
  ggplot(aes(x = response, y = data_value)) +
  geom_point() +
  facet_grid(. ~year) +
  labs(x = "Response", y = "Data value", title = "Data_value for responses")
```

* In NY, the distribution of data value in 2006 is similar as in 2010. The range of the group "Excellent", "Poor" and "Good" keeps same. The group "Very good" and the group "Fair" have a larger variation in 2010 compared to 2006. 

## Problem 3

```{r}
acc = read.csv("./accel_data.csv") %>%
  janitor::clean_names()
```

```{r}
acc_long = 
  acc %>%
  mutate(
    weekend_weekday = ifelse(day %in% c("Saturday","Sunday"), 0, 1),
    day = factor(day, levels = c("Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday")),
    week = as.integer(week),
    day_id = as.integer(day_id)
  ) %>%
  pivot_longer(activity_1:activity_1440,names_to = "actitity_id", values_to = "counts") %>%
  relocate("weekend_weekday", .after = day) 

acc_long %>% knitr::kable()
```

* There are six variables, including of `r colnames(acc)`. We can see the men activity counts for any minute on a observed day with the week id and day id. The number of observation is `r nrow(acc)`.

```{r}
daily_activity = 
  acc_long %>%
  group_by(week,day_id,day) %>%
  summarise(day_counts = sum(counts)) %>%
  knitr::kable()

daily_activity
```

* The men total daily activity counts varied from 100000 to 600000. But on Saturday of week 4 and week 5, the counts declined to 1440, an abnormal level. The men might forget to wear the devices or something wrong for the devices to get the data or the men had situation for his health.

```{r,fig.width = 10}
acc_hour =
  acc_long %>%
  mutate(
    hour_id = as.integer(round(row_number()/60) )
  ) %>%
  group_by(hour_id) %>%
  summarise(hour_counts = sum(counts))

acc_long %>%
  mutate(
    hour_id = as.integer(round(row_number()/60) )
  ) %>%
  left_join(acc_hour, by = "hour_id") %>%
  select(week,day_id,day,hour_id,hour_counts) %>%
  distinct() %>%
  ggplot(aes(x = hour_id, y = hour_counts, color = day, fill = day,alpha = 0.5)) +
  geom_point() +
  scale_x_continuous(
    breaks = seq(0, 875, by = 25),
    labels = seq(0, 35)) 
```

* On day 22 and day 29, the counts was extremely low, an abnormal level. The men might forget to wear the devices or something wrong for the devices to get the data or the men had situation for his health. Most of the day, the trend was like a thin downward parabola, reaching the peak at the middle of the day.